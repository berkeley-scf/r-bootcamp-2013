% R bootcamp, Module 3: Calculations
% August 2013, UC Berkeley
% Chris Paciorek and (add others)

# Vectorized calculations

Note: remember to start recording.

As we've seen, R has many functions that allow you to operate on each element of a vector all at once.

Advantages:
* much faster than looping
* easier to code
* easier to read and understand the code

```{r}
vals <- rnorm(1000)
chi2vals <- vals^2
chi2_df1000 <- sum(chi2vals)
# imagine if the code above were a loop, or three separate loops

vals <- rnorm(1e6)
system.time(trunc <- ifelse(vals > 0, vals, 0))
system.time(vals <- vals * (vals > 0))
```

```{r}
data=read.dta('../data/2004_labeled_processed_race.dta')
tmp <- as.character(data$age60)
data$ageMin <- substring(tmp, 1, 2)
```


# Linear algebra 

R can do essentially any linear algebra you need. It uses system-level package called BLAS (basic linear algebra subroutines) and LAPACK (linear algebra package). Note that these calculations will be essentially as fast as if you wrote C code as R just calls C and Fortran routines to do the calculations.

The BLAS that comes with R is fairly slow. It's possible to use a faster BLAS, as well as one that uses multiple cores automatically. This can in some cases give you an order of magnitude speedup if your work involves a lot of matrix manipulations/linear algebra.

See the R administration manual or talk to your systems manager. In the SCF we use something called *openBLAS* on the compute servers and *ACML* on the Linux cluster, and something called *vecLib* on the Macs.

# Vectorized vector/matrix calculations

Recall that `+`, `-`,`*`, `/` do vectorized calculations:

```{r}
A <- matrix(1:9, 3)
B <- matrix(seq(4,36, by = 4), 3)

A + B
A + B[ , 1]
A * B
A * B[ , 1]
```

Matrix/vector multiplication

```{r}
A %*% B[ , 1]
A %*% B

identical(t(A)%*%A, crossprod(A))
```

Some decompositions
```{r}
times <- seq(0, 1, length = 100)
R <- exp(-rdist(times) / 0.2)
e <- eigen(R)
range(e$values)
e$vectors[ , 1]

sv <- svd(R)
U <- chol(R)

devs <- rnorm(100)
Rinvb <- solve(R, devs)  # R^{-1} b
Rinv <- solve(R) # R^{-1} -- try to avoid this
```


# Pre-allocation

This is slow.
```{r}
vals <- 0
n <- 50000
system.time({
for(i in 1:n)
      vals <- c(vals, i)
})
```

The same holds for using `rbind()`, `cbind()`, or adding to a list, one element at a time.

This is slow and unclear:
```{r}
vals <- 0
n <- 50000
system.time({
for(i in 1:n)
      vals[i] <- i
})
```

# The answer is to pre-allocate memory

This is not so slow. (Please ignore the for-loop hypocrisy.)

```{r}
n <- 50000
system.time({
vals <- rep(NA, n)
# alternatively: vals <- as.numeric(NA); length(vals) <- n
for(i in 1:n)
      vals[i] <- i
})
```

Here's how to pre-allocate an empty list: `vals <- list(); length(vals) <- n`

# apply

Some functions aren't vectorized, or you may want to use a function on every row or column of a matrix/data frame, every element of a list, etc.

For this we use the `apply()` family of functions.

```{r}
mat <- matrix(rnorm(100*1000), nr = 100)
row_min <- apply(mat, 1, min)
col_max <- apply(mat, 2, max)
```

There are actually some even faster specialized functions:
```{r}
row_mean <- rowMeans(mat)
col_sum <- colSums(mat)
```

# `lapply()` and `sapply()`

```{r}
myList <- list(rnorm(3), rnorm(3), rnorm(5))
lapply(myList, min)
sapply(myList, min)
# why does this work?
lapply(data, class)
```

Note that we don't generally want to use `apply()` on a data frame. 

Here's a cool trick to pull off a particular element of a list of lists:

```{r}
params <- list(a = list(mn = 7, sd = 3), b = list(mn = 6,sd = 1), c = list(mn = 2, sd = 1))
sapply(params, "[[", 1)
```

Think about why this works. 

Hint:
```{r}
test <- list(5, 7, 3)
test[[2]]
`[[`(test, 2)
```

# And more apply()s

There are a bunch of apply variants, as well as parallelized versions of them (see Module 11, `?clusterApply`)

* `tapply()`, `vapply()`, `mapply()`, `rapply()`, `eapply()
* parallelized versions of various apply()s (see Module 11 or `?clusterApply`)

# Tabulation 

- Sometimes we need to do some basic checking for the number of observations or types of observations in our dataset
- To do this quickly and easily - the `table` function is our friend
- Let's look at our observations by year and grade

```{r table}
read.dta('../data/2004_labeled_processed_race.dta')
unique(data$pres04)
tbl <- table(data$race, data$pres04)
round(prop.table(tbl, margin = 1), 3)
table(data$race, data$pres04, data$sex)
with(data[data$sex == 'female', ], table(pres04, race))
```

# Stratified analyses I
Often we want to do individual analyses within subsets or clusters of our data.

As a first step, we might want to just split our dataset by a stratifying variable.

```{r}
data <- read.dta('../data/heights.dta')
subsets <- split(data, data$race)
length(subsets)
subsets[['9']]
```

The `%in%` operator can also be helpful.

```{r}
subset <- data[data$race %in% c(1, 2, 4), ]
```

# Stratified analyses II

Often we want to do individual analyses within subsets or clusters of our data. R has a variety of tools for this; for now we'll look at `aggregate()` and `by()`. These are wrappers of `tapply()`. 

```{r aggregate1}
data <- read.dta('../data/heights.dta')
aggregate(data, by = list(educ = data$ed), FUN = median, na.rm = TRUE)
aggregate(earn ~ ed, data = data, FUN = median)
aggregate(earn ~ ed + hisp, data = data, FUN = median)
agg <- aggregate(earn ~ ed + hisp, data = data, FUN = median)
xtabs(earn ~ ., data = agg)
```

There are also ways to produce output that can be used within a Latex table. (Don't ask me how, I don't know off the top of my head!)

# Stratified analyses III

`aggregate()` works fine when the output is univariate, but what about more complicated analyses than computing the median, such as fitting a set of regressions?

```{r}
data <- read.dta('../data/heights.dta')
out <- by(data, data$ed, function(x) {
if(sum(!is.na(x$earn))) 
lm(earn ~ height, data = x) 
else NA
} )
length(out)
summary(out[[5]])
```


# Sorting

`sort()` applied to a vector does what you expect.

Sorting a matrix or dataframe based on one or more columns is a somewhat manual process, but once you get the hang of it, it's not bad.

```{r}
data <- read.dta('../data/heights.dta')
ord <- order(data$earn, data$height, decreasing = TRUE)
# ord <- with(data, order(earn, height, decreasing = TRUE))
ord[1:5]
data$earn[ord][c(1:5, 2025:2029)]
data_ordered <- data[ord, ]
```

You could of course write your own *sort* function that uses `order()`.

# Merging Data

We often need to combine data across multiple data frames, merging on common fields (i.e., keys). This is basically a database join operation.

Here's an example using the voting data combined with a built-in R dataset on state information. Warning: the state dataset is *very* old; this is just a toy example. 

In this case (as often true) we need to do some machinations to get everything in order for the merge. The key we use is the state name.

```{r} 
data <- read.dta('../data/2004_labeled_processed_race.dta')
numToName <- data.frame(stateNum = 1:50, stateName = row.names(state.x77)) # a bit of querying indicates the state numbers are in alphabetical order
dataWithStateNames <- merge(data, numToName, by.x = 'state', by.y = 'stateNum', all.x = TRUE, all.y = FALSE)
stateInfo <- data.frame(state.x77)
stateInfo$name <- row.names(stateInfo) # need the names as column, not as the row names attribute
fullData <- merge(dataWithStateNames, stateInfo[ , c('name', 'Population', 'Income', 'Illiteracy', 'Life.Exp')], by.x  = 'stateName', by.y = 'name', all.x = TRUE, all.y = FALSE)
dim(data)
dim(fullData)
```

What's the deal with the `all.x` and `all.y` ?  We can tell R whether we want to keep all of the `x` observations, all the `y` observations or neither, or both, when there may be rows in either of the datasets that don't match the other dataset.

# Breakout

chi-square statistic - write vectorized
